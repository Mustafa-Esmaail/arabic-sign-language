{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ab9770b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d31ce92",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"ds\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2316d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classesNames=['ain', 'al', 'aleff','bb','dal','dha','dhad','fa','gaaf','ghain','ha','haa','jeem','kaaf','khaa','la','laam',\n",
    "        'meem','nun','ra','saad','seen','sheen','ta','taa','thaa','thal','toot','waw','ya','yaa','zay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8605e9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7959 images belonging to 32 classes.\n",
      "Found 1964 images belonging to 32 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1.0/255, validation_split=0.2)\n",
    "training_sets = datagen.flow_from_directory(\n",
    "        dataset_path,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        color_mode=\"rgb\",\n",
    "        classes = classesNames,\n",
    "\n",
    "        subset='training')\n",
    "\n",
    "\n",
    "test_sets = datagen.flow_from_directory(\n",
    "    dataset_path, # same directory as training data\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    color_mode=\"rgb\",\n",
    "    classes = classesNames,\n",
    "    subset='validation') # set as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b2883a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                401472    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 413,696\n",
      "Trainable params: 413,696\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "with tf.device('/device:GPU:0'): # render on gpu\n",
    "    # build a 6-layer\n",
    "    model = models.Sequential() # intial cnn\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3))) # step 1 add convulation  (feature maps)\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))  #3- pooling features\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu')) \n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "#     model.add(layers.Dense(128, activation='relu')) \n",
    "    model.add(layers.Dense(64, activation='relu')) \n",
    "    model.add(layers.Dense(32, activation='softmax'))\n",
    "    \n",
    "    \n",
    "#     model.add(layers.Conv2D(64,kernel_size=(5,5),activation='relu',input_shape=(100,100,3)))\n",
    "#     model.add(layers.Conv2D(215,kernel_size=(5,5),activation='relu'))\n",
    "#     model.add(layers.MaxPooling2D(pool_size=(4,4)))\n",
    "#     model.add(layers.Conv2D(120,kernel_size=(4,4),activation='relu'))\n",
    "#     model.add(layers.Conv2D(64,kernel_size=(5,5),activation='relu'))\n",
    "#     model.add(layers.Conv2D(75,kernel_size=(5,5),activation='relu'))\n",
    "#     model.add(layers.MaxPooling2D((4,4)))\n",
    "#     model.add(layers.Flatten())\n",
    "#     model.add(layers.Dense(200,activation='relu'))\n",
    "#     model.add(layers.Dense(128,activation='relu'))\n",
    "#     model.add(layers.Dense(64,activation='relu'))\n",
    "#     model.add(layers.Dense(4,activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4e37718",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55a89688",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "248/248 [==============================] - 49s 191ms/step - loss: 3.4661 - accuracy: 0.0333 - val_loss: 3.4501 - val_accuracy: 0.0348\n",
      "Epoch 2/50\n",
      "248/248 [==============================] - 47s 187ms/step - loss: 3.3382 - accuracy: 0.0796 - val_loss: 2.9739 - val_accuracy: 0.2177\n",
      "Epoch 3/50\n",
      "248/248 [==============================] - 49s 197ms/step - loss: 2.7094 - accuracy: 0.2447 - val_loss: 1.9685 - val_accuracy: 0.4672\n",
      "Epoch 4/50\n",
      "248/248 [==============================] - 47s 189ms/step - loss: 1.8414 - accuracy: 0.4769 - val_loss: 1.1376 - val_accuracy: 0.7111\n",
      "Epoch 5/50\n",
      "248/248 [==============================] - 47s 191ms/step - loss: 1.0685 - accuracy: 0.7000 - val_loss: 0.5877 - val_accuracy: 0.8576\n",
      "Epoch 6/50\n",
      "248/248 [==============================] - 48s 194ms/step - loss: 0.5272 - accuracy: 0.8514 - val_loss: 0.3036 - val_accuracy: 0.9242\n",
      "Epoch 7/50\n",
      "248/248 [==============================] - 48s 191ms/step - loss: 0.2721 - accuracy: 0.9285 - val_loss: 0.1662 - val_accuracy: 0.9672\n",
      "Epoch 8/50\n",
      "248/248 [==============================] - 47s 191ms/step - loss: 0.1377 - accuracy: 0.9686 - val_loss: 0.0898 - val_accuracy: 0.9841\n",
      "Epoch 9/50\n",
      "248/248 [==============================] - 51s 207ms/step - loss: 0.0933 - accuracy: 0.9783 - val_loss: 0.0364 - val_accuracy: 0.9949\n",
      "Epoch 10/50\n",
      "248/248 [==============================] - 86s 346ms/step - loss: 0.0747 - accuracy: 0.9850 - val_loss: 0.0588 - val_accuracy: 0.9877\n",
      "Epoch 11/50\n",
      "248/248 [==============================] - 46s 186ms/step - loss: 0.0693 - accuracy: 0.9851 - val_loss: 0.0652 - val_accuracy: 0.9867\n",
      "Epoch 12/50\n",
      "248/248 [==============================] - 46s 186ms/step - loss: 0.1054 - accuracy: 0.9738 - val_loss: 0.0952 - val_accuracy: 0.9759\n",
      "Epoch 13/50\n",
      "248/248 [==============================] - 47s 191ms/step - loss: 0.1083 - accuracy: 0.9726 - val_loss: 0.0788 - val_accuracy: 0.9826\n",
      "Epoch 14/50\n",
      "248/248 [==============================] - 47s 189ms/step - loss: 0.0541 - accuracy: 0.9876 - val_loss: 0.0831 - val_accuracy: 0.9928\n",
      "Epoch 15/50\n",
      "248/248 [==============================] - 47s 187ms/step - loss: 0.0451 - accuracy: 0.9928 - val_loss: 0.0200 - val_accuracy: 0.9964\n",
      "Epoch 16/50\n",
      "248/248 [==============================] - 46s 187ms/step - loss: 0.0267 - accuracy: 0.9956 - val_loss: 0.0086 - val_accuracy: 0.9990\n",
      "Epoch 17/50\n",
      "248/248 [==============================] - 47s 190ms/step - loss: 0.0269 - accuracy: 0.9955 - val_loss: 0.0120 - val_accuracy: 0.9980\n",
      "Epoch 18/50\n",
      "248/248 [==============================] - 47s 190ms/step - loss: 0.0337 - accuracy: 0.9937 - val_loss: 0.0269 - val_accuracy: 0.9923\n",
      "Epoch 19/50\n",
      "248/248 [==============================] - 47s 190ms/step - loss: 0.0771 - accuracy: 0.9807 - val_loss: 0.0676 - val_accuracy: 0.9836\n",
      "Epoch 20/50\n",
      "248/248 [==============================] - 47s 188ms/step - loss: 0.0602 - accuracy: 0.9852 - val_loss: 0.0297 - val_accuracy: 0.9928\n",
      "Epoch 21/50\n",
      "248/248 [==============================] - 47s 188ms/step - loss: 0.0340 - accuracy: 0.9923 - val_loss: 0.0524 - val_accuracy: 0.9857\n",
      "Epoch 22/50\n",
      "248/248 [==============================] - 47s 189ms/step - loss: 0.0543 - accuracy: 0.9874 - val_loss: 0.0579 - val_accuracy: 0.9831\n",
      "Epoch 23/50\n",
      "248/248 [==============================] - 48s 192ms/step - loss: 0.1125 - accuracy: 0.9730 - val_loss: 0.0628 - val_accuracy: 0.9846\n",
      "Epoch 24/50\n",
      "248/248 [==============================] - 47s 189ms/step - loss: 0.0460 - accuracy: 0.9881 - val_loss: 0.0362 - val_accuracy: 0.9908\n",
      "Epoch 25/50\n",
      "248/248 [==============================] - 47s 189ms/step - loss: 0.0230 - accuracy: 0.9958 - val_loss: 0.0167 - val_accuracy: 0.9969\n",
      "Epoch 26/50\n",
      "248/248 [==============================] - 46s 187ms/step - loss: 0.0150 - accuracy: 0.9971 - val_loss: 0.0089 - val_accuracy: 0.9980\n",
      "Epoch 27/50\n",
      "248/248 [==============================] - 46s 186ms/step - loss: 0.0083 - accuracy: 0.9984 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "248/248 [==============================] - 48s 192ms/step - loss: 0.0084 - accuracy: 0.9992 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "248/248 [==============================] - 47s 190ms/step - loss: 0.0037 - accuracy: 0.9996 - val_loss: 6.1258e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "248/248 [==============================] - 47s 190ms/step - loss: 0.0048 - accuracy: 0.9996 - val_loss: 7.0377e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "248/248 [==============================] - 47s 188ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 4.4286e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "248/248 [==============================] - 47s 189ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.0108 - val_accuracy: 0.9995\n",
      "Epoch 33/50\n",
      "248/248 [==============================] - 48s 192ms/step - loss: 0.0052 - accuracy: 0.9995 - val_loss: 3.6154e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "248/248 [==============================] - 46s 186ms/step - loss: 0.0030 - accuracy: 0.9997 - val_loss: 3.0688e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "248/248 [==============================] - 47s 190ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 0.0067 - val_accuracy: 0.9995\n",
      "Epoch 36/50\n",
      "248/248 [==============================] - 46s 185ms/step - loss: 0.0040 - accuracy: 0.9996 - val_loss: 0.0080 - val_accuracy: 0.9990\n",
      "Epoch 37/50\n",
      "248/248 [==============================] - 46s 187ms/step - loss: 0.0044 - accuracy: 0.9995 - val_loss: 3.5137e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "248/248 [==============================] - 47s 188ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 9.2469e-04 - val_accuracy: 0.9995\n",
      "Epoch 39/50\n",
      "248/248 [==============================] - 46s 186ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 2.2870e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "248/248 [==============================] - 47s 189ms/step - loss: 0.0044 - accuracy: 0.9996 - val_loss: 6.2428e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "248/248 [==============================] - 47s 188ms/step - loss: 0.1343 - accuracy: 0.9671 - val_loss: 0.5262 - val_accuracy: 0.8632\n",
      "Epoch 42/50\n",
      "248/248 [==============================] - 47s 189ms/step - loss: 0.3316 - accuracy: 0.9089 - val_loss: 0.0817 - val_accuracy: 0.9836\n",
      "Epoch 43/50\n",
      "248/248 [==============================] - 47s 189ms/step - loss: 0.0609 - accuracy: 0.9839 - val_loss: 0.0108 - val_accuracy: 0.9980\n",
      "Epoch 44/50\n",
      "248/248 [==============================] - 47s 189ms/step - loss: 0.0135 - accuracy: 0.9967 - val_loss: 0.0051 - val_accuracy: 0.9985\n",
      "Epoch 45/50\n",
      "248/248 [==============================] - 46s 184ms/step - loss: 0.0069 - accuracy: 0.9991 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "248/248 [==============================] - 46s 185ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.0029 - val_accuracy: 0.9995\n",
      "Epoch 47/50\n",
      "248/248 [==============================] - 47s 190ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "248/248 [==============================] - 47s 189ms/step - loss: 0.0061 - accuracy: 0.9992 - val_loss: 8.4737e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "248/248 [==============================] - 46s 186ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 4.3905e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "248/248 [==============================] - 47s 191ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 3.6097e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x128af175be0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_sets,\n",
    "                    validation_data = training_sets,\n",
    "                    steps_per_epoch = training_sets.n//training_sets.batch_size,\n",
    "                    validation_steps = test_sets.n//test_sets.batch_size,\n",
    "                    epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f9f250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('sign-lang-ar.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce2bd314",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '1_21_M_nun_0.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_61044\\1648661865.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m img=tf.keras.preprocessing.image.load_img(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;34m'1_21_M_nun_0.jpg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrayscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"rgb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\image_utils.py\u001b[0m in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m             \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1_21_M_nun_0.jpg'"
     ]
    }
   ],
   "source": [
    "img=tf.keras.preprocessing.image.load_img(\n",
    "    '1_21_M_nun_0.jpg', grayscale=False, color_mode=\"rgb\", target_size=(64, 64)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6a3f43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e3097f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
